{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors, linear_model, multioutput\n",
    "import tensorflow as tf\n",
    "import pycountry\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import lang2vec.lang2vec as l2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[2], \"GPU\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifyer(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, units1, units2, units3):\n",
    "        \n",
    "        super(Classifyer, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units1, activation=tf.math.sigmoid)\n",
    "        self.dense2 = tf.keras.layers.Dense(units2, activation=tf.math.sigmoid)\n",
    "        self.dense3 = tf.keras.layers.Dense(units3, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    return loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, inputs, label):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pre = model(inputs)\n",
    "        loss = loss_function(label, pre)\n",
    "        \n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"/data/rrjin/Graduation/data/bible-corpus/parallel_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_alpha3(language_code):\n",
    "    if len(language_code) == 2:\n",
    "        ans = pycountry.languages.get(alpha_2 = language_code)\n",
    "    elif len(language_code) == 3:\n",
    "        ans = pycountry.languages.get(alpha_3 = language_code)\n",
    "    else:\n",
    "        return \"-1\"\n",
    "    if ans is not None:\n",
    "        return ans.alpha_3\n",
    "    else:\n",
    "        return \"unknown language\"\n",
    "\n",
    "\n",
    "def check_alpha3(alpha3):\n",
    "    if alpha3 != \"unknown language\" and alpha3 in l2v.LANGUAGES:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "langcode_to_alpha3 = {\"jap\": \"jpn\"}\n",
    "\n",
    "for lang in os.listdir(source_dir):\n",
    "    # Get ISO 639-3 codes according to abbreviations of languages\n",
    "    s = lang[:-4]\n",
    "    language1, language2 = s.split(\"-\")\n",
    "    language1_alpha3, language2_alpha3 = get_language_alpha3(language1), get_language_alpha3(language2)\n",
    "    if check_alpha3(language1_alpha3):\n",
    "        langcode_to_alpha3[language1] = language1_alpha3\n",
    "    if check_alpha3(language2_alpha3):\n",
    "        langcode_to_alpha3[language2] = language2_alpha3\n",
    "\n",
    "langcode_to_alpha3.pop(\"en\")\n",
    "\n",
    "lang_alpha3 = list(langcode_to_alpha3.values())\n",
    "feature_name = \"syntax_wals\"\n",
    "features = l2v.get_features(lang_alpha3, feature_name, header=True)\n",
    "\n",
    "features_geo = l2v.get_features(lang_alpha3, \"geo\", header=True)\n",
    "\n",
    "lang_alpha3.sort()  # fix order\n",
    "\n",
    "X = [features_geo[lang] for lang in lang_alpha3]\n",
    "train_data_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature S_SVO accuracy is 0.5789473652839661, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_SOV accuracy is 0.4736842215061188, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_VSO accuracy is 0.8947368264198303, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_VOS accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_OVS has only one class!\n",
      "Feature S_OSV has only one class!\n",
      "Feature S_SUBJECT_BEFORE_VERB accuracy is 0.8095238208770752, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_SUBJECT_AFTER_VERB accuracy is 0.6666666865348816, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_OBJECT_AFTER_VERB accuracy is 0.761904776096344, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_OBJECT_BEFORE_VERB accuracy is 0.5714285969734192, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_SUBJECT_BEFORE_OBJECT accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_SUBJECT_AFTER_OBJECT accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_GENDER_MARK accuracy is 0.4545454680919647, train dataset has 25 element, test dataset has 11 element\n",
      "Feature S_SEX_MARK accuracy is 0.27272728085517883, train dataset has 25 element, test dataset has 11 element\n",
      "Feature S_DEFINITE_AFFIX accuracy is 0.8235294222831726, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_DEFINITE_WORD accuracy is 0.7647058963775635, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_INDEFINITE_AFFIX has only one class!\n",
      "Feature S_INDEFINITE_WORD accuracy is 0.4375, train dataset has 36 element, test dataset has 16 element\n",
      "Feature S_POSSESSIVE_PREFIX accuracy is 1.0, train dataset has 32 element, test dataset has 14 element\n",
      "Feature S_POSSESSIVE_SUFFIX accuracy is 0.5, train dataset has 32 element, test dataset has 14 element\n",
      "Feature S_ADPOSITION_BEFORE_NOUN accuracy is 0.4000000059604645, train dataset has 44 element, test dataset has 20 element\n",
      "Feature S_ADPOSITION_AFTER_NOUN accuracy is 0.30000001192092896, train dataset has 44 element, test dataset has 20 element\n",
      "Feature S_POSSESSOR_BEFORE_NOUN accuracy is 0.523809552192688, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_POSSESSOR_AFTER_NOUN accuracy is 0.4761904776096344, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_ADJECTIVE_BEFORE_NOUN accuracy is 0.8571428656578064, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_ADJECTIVE_AFTER_NOUN accuracy is 0.9047619104385376, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_DEMONSTRATIVE_WORD_BEFORE_NOUN accuracy is 0.6666666865348816, train dataset has 40 element, test dataset has 18 element\n",
      "Feature S_DEMONSTRATIVE_WORD_AFTER_NOUN accuracy is 0.6666666865348816, train dataset has 40 element, test dataset has 18 element\n",
      "Feature S_DEMONSTRATIVE_PREFIX has only one class!\n",
      "Feature S_DEMONSTRATIVE_SUFFIX has only one class!\n",
      "Feature S_NUMERAL_BEFORE_NOUN accuracy is 0.8500000238418579, train dataset has 44 element, test dataset has 20 element\n",
      "Feature S_NUMERAL_AFTER_NOUN accuracy is 0.8500000238418579, train dataset has 44 element, test dataset has 20 element\n",
      "Feature S_RELATIVE_BEFORE_NOUN accuracy is 0.6111111044883728, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_RELATIVE_AFTER_NOUN accuracy is 0.7777777910232544, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_RELATIVE_AROUND_NOUN has only one class!\n",
      "Feature S_NOMINATIVE_VS_ACCUSATIVE_MARK accuracy is 0.3333333432674408, train dataset has 20 element, test dataset has 9 element\n",
      "Feature S_ERGATIVE_VS_ABSOLUTIVE_MARK has only one class!\n",
      "Feature S_NEGATIVE_WORD_BEFORE_VERB accuracy is 0.5714285969734192, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_NEGATIVE_PREFIX accuracy is 0.7142857313156128, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_NEGATIVE_WORD_AFTER_VERB accuracy is 0.8095238208770752, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_NEGATIVE_SUFFIX accuracy is 0.6666666865348816, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_NEGATIVE_WORD_BEFORE_SUBJECT accuracy is 0.7333333492279053, train dataset has 34 element, test dataset has 15 element\n",
      "Feature S_NEGATIVE_WORD_AFTER_SUBJECT accuracy is 0.6666666865348816, train dataset has 34 element, test dataset has 15 element\n",
      "Feature S_NEGATIVE_WORD_BEFORE_OBJECT accuracy is 0.7333333492279053, train dataset has 34 element, test dataset has 15 element\n",
      "Feature S_NEGATIVE_WORD_AFTER_OBJECT accuracy is 0.8666666746139526, train dataset has 34 element, test dataset has 15 element\n",
      "Feature S_NEGATIVE_WORD_INITIAL accuracy is 1.0, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_NEGATIVE_WORD_FINAL accuracy is 1.0, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_NEGATIVE_WORD_ADJACENT_BEFORE_VERB accuracy is 0.529411792755127, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_NEGATIVE_WORD_ADJACENT_AFTER_VERB accuracy is 0.7647058963775635, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_PLURAL_PREFIX accuracy is 0.8235294222831726, train dataset has 37 element, test dataset has 17 element\n",
      "Feature S_PLURAL_SUFFIX accuracy is 0.8235294222831726, train dataset has 37 element, test dataset has 17 element\n",
      "Feature S_PLURAL_WORD accuracy is 0.9411764740943909, train dataset has 37 element, test dataset has 17 element\n",
      "Feature S_OBJECT_HEADMARK accuracy is 0.6666666865348816, train dataset has 21 element, test dataset has 9 element\n",
      "Feature S_OBJECT_DEPMARK accuracy is 0.6666666865348816, train dataset has 21 element, test dataset has 9 element\n",
      "Feature S_POSSESSIVE_HEADMARK accuracy is 0.7777777910232544, train dataset has 19 element, test dataset has 9 element\n",
      "Feature S_POSSESSIVE_DEPMARK accuracy is 0.6666666865348816, train dataset has 19 element, test dataset has 9 element\n",
      "Feature S_TEND_HEADMARK accuracy is 0.8888888955116272, train dataset has 21 element, test dataset has 9 element\n",
      "Feature S_TEND_DEPMARK accuracy is 0.4444444477558136, train dataset has 21 element, test dataset has 9 element\n",
      "Feature S_TEND_PREFIX accuracy is 0.75, train dataset has 45 element, test dataset has 20 element\n",
      "Feature S_TEND_SUFFIX accuracy is 0.699999988079071, train dataset has 45 element, test dataset has 20 element\n",
      "Feature S_ANY_REDUP accuracy is 0.8333333134651184, train dataset has 27 element, test dataset has 12 element\n",
      "Feature S_CASE_PREFIX has only one class!\n",
      "Feature S_CASE_SUFFIX accuracy is 0.5, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_CASE_PROCLITIC accuracy is 1.0, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_CASE_ENCLITIC accuracy is 0.9444444179534912, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_CASE_MARK accuracy is 0.6111111044883728, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_COMITATIVE_VS_INSTRUMENTAL_MARK accuracy is 0.5833333134651184, train dataset has 28 element, test dataset has 12 element\n",
      "Feature S_NUMCLASS_MARK accuracy is 0.699999988079071, train dataset has 22 element, test dataset has 10 element\n",
      "Feature S_ADJECTIVE_WITHOUT_NOUN accuracy is 0.7142857313156128, train dataset has 15 element, test dataset has 7 element\n",
      "Feature S_PERFECTIVE_VS_IMPERFECTIVE_MARK accuracy is 0.7692307829856873, train dataset has 28 element, test dataset has 13 element\n",
      "Feature S_PAST_VS_PRESENT_MARK accuracy is 0.7692307829856873, train dataset has 28 element, test dataset has 13 element\n",
      "Feature S_FUTURE_AFFIX accuracy is 0.38461539149284363, train dataset has 28 element, test dataset has 13 element\n",
      "Feature S_TAM_PREFIX accuracy is 0.9411764740943909, train dataset has 37 element, test dataset has 17 element\n",
      "Feature S_TAM_SUFFIX accuracy is 0.7647058963775635, train dataset has 37 element, test dataset has 17 element\n",
      "Feature S_DEGREE_WORD_BEFORE_ADJECTIVE accuracy is 0.8571428656578064, train dataset has 32 element, test dataset has 14 element\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature S_DEGREE_WORD_AFTER_ADJECTIVE accuracy is 0.5714285969734192, train dataset has 32 element, test dataset has 14 element\n",
      "Feature S_POLARQ_MARK_INITIAL accuracy is 0.7647058963775635, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_POLARQ_MARK_FINAL accuracy is 0.5882353186607361, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_POLARQ_MARK_SECOND accuracy is 0.8235294222831726, train dataset has 38 element, test dataset has 17 element\n",
      "Feature S_POLARQ_WORD accuracy is 0.44999998807907104, train dataset has 45 element, test dataset has 20 element\n",
      "Feature S_POLARQ_AFFIX accuracy is 0.699999988079071, train dataset has 45 element, test dataset has 20 element\n",
      "Feature S_SUBORDINATOR_WORD_BEFORE_CLAUSE accuracy is 0.5, train dataset has 36 element, test dataset has 16 element\n",
      "Feature S_SUBORDINATOR_WORD_AFTER_CLAUSE accuracy is 0.875, train dataset has 36 element, test dataset has 16 element\n",
      "Feature S_SUBORDINATOR_SUFFIX accuracy is 0.5625, train dataset has 36 element, test dataset has 16 element\n",
      "Feature S_PROSUBJECT_WORD accuracy is 0.6000000238418579, train dataset has 33 element, test dataset has 15 element\n",
      "Feature S_PROSUBJECT_AFFIX accuracy is 0.6000000238418579, train dataset has 33 element, test dataset has 15 element\n",
      "Feature S_PROSUBJECT_CLITIC has only one class!\n",
      "Feature S_NEGATIVE_AFFIX accuracy is 0.6111111044883728, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_NEGATIVE_WORD accuracy is 0.7777777910232544, train dataset has 42 element, test dataset has 18 element\n",
      "Feature S_ANY_AGREEMENT_ON_ADJECTIVES is not available in all 101 languages!\n",
      "Feature S_COMPLEMENTIZER_WORD_BEFORE_CLAUSE is not available in all 101 languages!\n",
      "Feature S_COMPLEMENTIZER_WORD_AFTER_CLAUSE is not available in all 101 languages!\n",
      "Feature S_VOX accuracy is 0.8571428656578064, train dataset has 14 element, test dataset has 7 element\n",
      "Feature S_XVO has only one class!\n",
      "Feature S_XOV has only one class!\n",
      "Feature S_OXV accuracy is 0.8571428656578064, train dataset has 14 element, test dataset has 7 element\n",
      "Feature S_OVX has only one class!\n",
      "Feature S_OBLIQUE_AFTER_VERB accuracy is 0.8571428656578064, train dataset has 14 element, test dataset has 7 element\n",
      "Feature S_OBLIQUE_AFTER_OBJECT has only one class!\n",
      "Feature S_OBLIQUE_BEFORE_VERB accuracy is 0.8571428656578064, train dataset has 14 element, test dataset has 7 element\n",
      "Feature S_OBLIQUE_BEFORE_OBJECT has only one class!\n",
      "Feature S_ARTICLE_WORD_BEFORE_NOUN is not available in all 101 languages!\n",
      "Feature S_ARTICLE_WORD_AFTER_NOUN is not available in all 101 languages!\n"
     ]
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for feat in range(len(features[\"CODE\"])):\n",
    "    Y = [features[lang][feat] if features[lang][feat] != \"--\" else -1 for lang in lang_alpha3]\n",
    "\n",
    "    idx = [i for i in range(len(Y)) if Y[i] != -1]\n",
    "\n",
    "    train_set = np.array([(X[i], Y[i]) for i in idx])\n",
    "\n",
    "    if len(train_set) == 0:\n",
    "        print(\"Feature {} is not available in all 101 languages!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    train_set[:, 1] = lab_enc.fit_transform(train_set[:, 1])\n",
    "\n",
    "    X_train = train_set[:int(len(train_set) * train_data_rate), 0]\n",
    "    Y_train = train_set[:int(len(train_set) * train_data_rate), 1]\n",
    "    \n",
    "    X_test = train_set[int(len(train_set) * train_data_rate):, 0]\n",
    "    Y_test = train_set[int(len(train_set) * train_data_rate):, 1]\n",
    "\n",
    "    if len(X_train) == 0:\n",
    "        print(\"Feature {} has no train data!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    if len(X_test) == 0:\n",
    "        print(\"Feature {} has no test data!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    if np.all(Y_train == Y_train[0]):\n",
    "        print(\"Feature {} has only one class!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "    \n",
    "    X_train = tf.convert_to_tensor(X_train.tolist(), dtype=tf.float32)\n",
    "    Y_train = tf.convert_to_tensor(Y_train.tolist(), dtype=tf.float32)\n",
    "    \n",
    "    X_test = tf.convert_to_tensor(X_test.tolist(), dtype=tf.float32)\n",
    "    Y_test = tf.convert_to_tensor(Y_test.tolist(), dtype=tf.float32)\n",
    "    \n",
    "#     print(X_train.dtype)\n",
    "#     print(Y_train.shape)\n",
    "    \n",
    "    model = Classifyer(50, 50, 2)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    EPOCHS = 10000\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_epoch(model, optimizer, X_train, Y_train)\n",
    "        \n",
    "#         if epoch % 10000 == 0:\n",
    "#             print(\"Loss is {}\".format(loss))\n",
    "    \n",
    "    predict_y = model(X_test)\n",
    "    predict_y = tf.math.argmax(predict_y, axis=1)\n",
    "    \n",
    "    predict_y = tf.cast(predict_y, dtype=tf.float32)\n",
    "    \n",
    "    score = tf.math.reduce_sum(tf.cast(tf.math.equal(Y_test, predict_y), dtype=tf.float32)) / predict_y.shape[0]\n",
    "    \n",
    "#     logistic_model = linear_model.LogisticRegression(max_iter=3000)\n",
    "#     clf = logistic_model.fit(X_train.tolist(), Y_train.tolist())\n",
    "#     score = clf.score(X_test.tolist(), Y_test.tolist())\n",
    "    score_dict[features[\"CODE\"][feat]] = score\n",
    "    print(\"Feature {} accuracy is {}, train dataset has {} element, test dataset has {} element\".format(features[\"CODE\"][feat], score, len(X_train), len(X_test)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
