{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, neighbors, linear_model, multioutput\n",
    "import tensorflow as tf\n",
    "import pycountry\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import lang2vec.lang2vec as l2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[2], \"GPU\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifyer(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, units1, units2, units3):\n",
    "        \n",
    "        super(Classifyer, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units1, activation=tf.math.sigmoid)\n",
    "        self.dense2 = tf.keras.layers.Dense(units2, activation=tf.math.sigmoid)\n",
    "        self.dense3 = tf.keras.layers.Dense(units3, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    return loss_object(real, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, inputs, label):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        pre = model(inputs)\n",
    "        loss = loss_function(label, pre)\n",
    "        \n",
    "    variables = model.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"/data/rrjin/Graduation/data/bible-corpus/parallel_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_alpha3(language_code):\n",
    "    if len(language_code) == 2:\n",
    "        ans = pycountry.languages.get(alpha_2 = language_code)\n",
    "    elif len(language_code) == 3:\n",
    "        ans = pycountry.languages.get(alpha_3 = language_code)\n",
    "    else:\n",
    "        return \"-1\"\n",
    "    if ans is not None:\n",
    "        return ans.alpha_3\n",
    "    else:\n",
    "        return \"unknown language\"\n",
    "\n",
    "\n",
    "def check_alpha3(alpha3):\n",
    "    if alpha3 != \"unknown language\" and alpha3 in l2v.LANGUAGES:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "langcode_to_alpha3 = {\"jap\": \"jpn\"}\n",
    "\n",
    "for lang in os.listdir(source_dir):\n",
    "    # Get ISO 639-3 codes according to abbreviations of languages\n",
    "    s = lang[:-4]\n",
    "    language1, language2 = s.split(\"-\")\n",
    "    language1_alpha3, language2_alpha3 = get_language_alpha3(language1), get_language_alpha3(language2)\n",
    "    if check_alpha3(language1_alpha3):\n",
    "        langcode_to_alpha3[language1] = language1_alpha3\n",
    "    if check_alpha3(language2_alpha3):\n",
    "        langcode_to_alpha3[language2] = language2_alpha3\n",
    "\n",
    "langcode_to_alpha3.pop(\"en\")\n",
    "\n",
    "lang_alpha3 = list(langcode_to_alpha3.values())\n",
    "feature_name = \"syntax_wals\"\n",
    "features = l2v.get_features(lang_alpha3, feature_name, header=True)\n",
    "\n",
    "features_geo = l2v.get_features(lang_alpha3, \"geo\", header=True)\n",
    "\n",
    "lang_alpha3.sort()  # fix order\n",
    "\n",
    "X = [features_geo[lang] for lang in lang_alpha3]\n",
    "train_data_rate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature S_SVO accuracy is 0.5789473652839661, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_SOV accuracy is 0.4736842215061188, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_VSO accuracy is 0.8947368264198303, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_VOS accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_OVS has only one class!\n",
      "Feature S_OSV has only one class!\n",
      "Feature S_SUBJECT_BEFORE_VERB accuracy is 0.8095238208770752, train dataset has 49 element, test dataset has 21 element\n",
      "Feature S_SUBJECT_AFTER_VERB accuracy is 0.6666666865348816, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_OBJECT_AFTER_VERB accuracy is 0.761904776096344, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_OBJECT_BEFORE_VERB accuracy is 0.5714285969734192, train dataset has 47 element, test dataset has 21 element\n",
      "Feature S_SUBJECT_BEFORE_OBJECT accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_SUBJECT_AFTER_OBJECT accuracy is 0.8421052694320679, train dataset has 44 element, test dataset has 19 element\n",
      "Feature S_GENDER_MARK accuracy is 0.4545454680919647, train dataset has 25 element, test dataset has 11 element\n"
     ]
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for feat in range(len(features[\"CODE\"])):\n",
    "    Y = [features[lang][feat] if features[lang][feat] != \"--\" else -1 for lang in lang_alpha3]\n",
    "\n",
    "    idx = [i for i in range(len(Y)) if Y[i] != -1]\n",
    "\n",
    "    train_set = np.array([(X[i], Y[i]) for i in idx])\n",
    "\n",
    "    if len(train_set) == 0:\n",
    "        print(\"Feature {} is not available in all 101 languages!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    train_set[:, 1] = lab_enc.fit_transform(train_set[:, 1])\n",
    "\n",
    "    X_train = train_set[:int(len(train_set) * train_data_rate), 0]\n",
    "    Y_train = train_set[:int(len(train_set) * train_data_rate), 1]\n",
    "    \n",
    "    X_test = train_set[int(len(train_set) * train_data_rate):, 0]\n",
    "    Y_test = train_set[int(len(train_set) * train_data_rate):, 1]\n",
    "\n",
    "    if len(X_train) == 0:\n",
    "        print(\"Feature {} has no train data!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    if len(X_test) == 0:\n",
    "        print(\"Feature {} has no test data!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "\n",
    "    if np.all(Y_train == Y_train[0]):\n",
    "        print(\"Feature {} has only one class!\".format(features[\"CODE\"][feat]))\n",
    "        continue\n",
    "    \n",
    "    X_train = tf.convert_to_tensor(X_train.tolist(), dtype=tf.float32)\n",
    "    Y_train = tf.convert_to_tensor(Y_train.tolist(), dtype=tf.float32)\n",
    "    \n",
    "    X_test = tf.convert_to_tensor(X_test.tolist(), dtype=tf.float32)\n",
    "    Y_test = tf.convert_to_tensor(Y_test.tolist(), dtype=tf.float32)\n",
    "    \n",
    "#     print(X_train.dtype)\n",
    "#     print(Y_train.shape)\n",
    "    \n",
    "    model = Classifyer(50, 50, 2)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    EPOCHS = 10000\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_epoch(model, optimizer, X_train, Y_train)\n",
    "        \n",
    "#         if epoch % 10000 == 0:\n",
    "#             print(\"Loss is {}\".format(loss))\n",
    "    \n",
    "    predict_y = model(X_test)\n",
    "    predict_y = tf.math.argmax(predict_y, axis=1)\n",
    "    \n",
    "    predict_y = tf.cast(predict_y, dtype=tf.float32)\n",
    "    \n",
    "    score = tf.math.reduce_sum(tf.cast(tf.math.equal(Y_test, predict_y), dtype=tf.float32)) / predict_y.shape[0]\n",
    "    \n",
    "#     logistic_model = linear_model.LogisticRegression(max_iter=3000)\n",
    "#     clf = logistic_model.fit(X_train.tolist(), Y_train.tolist())\n",
    "#     score = clf.score(X_test.tolist(), Y_test.tolist())\n",
    "    score_dict[features[\"CODE\"][feat]] = score\n",
    "    print(\"Feature {} accuracy is {}, train dataset has {} element, test dataset has {} element\".format(features[\"CODE\"][feat], score, len(X_train), len(X_test)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
